bleu_score_gpt4o_0shot = {'bleu': 0.09432160921711255, 'precisions': [0.37121488507843853, 0.13127258129265354, 0.06671128960285587, 0.03992968357609242], 'brevity_penalty': 0.8836647856905493, 'length_ratio': 0.8899350649350649, 'translation_length': 5482, 'reference_length': 6160}
bleu_score_gpt4o_0shot_cot = {'bleu': 0.09903280100423822, 'precisions': [0.37531899380240613, 0.1327717609306057, 0.06910387873383861, 0.04565980933266432], 'brevity_penalty': 0.8843890737735954, 'length_ratio': 0.8905844155844156, 'translation_length': 5486, 'reference_length': 6160}
bleu_score_gpt4o_5shot = {'bleu': 0.1260566331878853, 'precisions': [0.3927749247387994, 0.15659607538371867, 0.09489993544222079, 0.06221364842054497], 'brevity_penalty': 0.9131595169401368, 'length_ratio': 0.9167207792207792, 'translation_length': 5647, 'reference_length': 6160}
bleu_score_gpt4o_5shot_cot = {'bleu': 0.12250509632186748, 'precisions': [0.39685345589535087, 0.15726197401590072, 0.08846897144084175, 0.05821505893673322], 'brevity_penalty': 0.9149220699590098, 'length_ratio': 0.9183441558441559, 'translation_length': 5657, 'reference_length': 6160}
bleu_score_gpt4o_10shot = {'bleu': 0.15496390102385285, 'precisions': [0.4025804344275682, 0.1689489596300907, 0.10911575248877611, 0.07960199004975124], 'brevity_penalty': 0.993975431449857, 'length_ratio': 0.9939935064935065, 'translation_length': 6123, 'reference_length': 6160}
bleu_score_gpt4o_10shot_cot = {'bleu': 0.13080991766494163, 'precisions': [0.3906532828698371, 0.14918414918414918, 0.08863502068150482, 0.05986454009176316], 'brevity_penalty': 0.9864347930827618, 'length_ratio': 0.986525974025974, 'translation_length': 6077, 'reference_length': 6160}
bleu_score_gpt4turbo_0shot = {'bleu': 0.09571482497958371, 'precisions': [0.37163219189987834, 0.12430991814201409, 0.0629076372817168, 0.038325887608746764], 'brevity_penalty': 0.9316987949670262, 'length_ratio': 0.9339285714285714, 'translation_length': 5753, 'reference_length': 6160}
bleu_score_gpt4turbo_0shot_cot = {'bleu': 0.09700493947387337, 'precisions': [0.3814270724029381, 0.12993484093522423, 0.06337431114879186, 0.03840682788051209], 'brevity_penalty': 0.9256123549389819, 'length_ratio': 0.9282467532467532, 'translation_length': 5718, 'reference_length': 6160}
bleu_score_gpt4turbo_5shot = {'bleu': 0.14252078881556568, 'precisions': [0.39251355606087107, 0.16522905884608013, 0.10917956328174687, 0.07944036044581455], 'brevity_penalty': 0.9254379508778183, 'length_ratio': 0.9280844155844156, 'translation_length': 5717, 'reference_length': 6160}
bleu_score_gpt4turbo_5shot_cot = {'bleu': 0.1482847945602524, 'precisions': [0.3909813407049067, 0.17265506807866868, 0.11445279866332497, 0.08092350746268656], 'brevity_penalty': 0.9377509234017409, 'length_ratio': 0.9396103896103896, 'translation_length': 5788, 'reference_length': 6160}
bleu_score_gpt4turbo_10shot = {'bleu': 0.13379689835088182, 'precisions': [0.38492381716118684, 0.15170008718395817, 0.09054441260744986, 0.06061246040126716], 'brevity_penalty': 1.0, 'length_ratio': 1.0121753246753247, 'translation_length': 6235, 'reference_length': 6160}
bleu_score_gpt4turbo_10shot_cot = {'bleu': 0.1467382083696358, 'precisions': [0.3897955949928696, 0.16227843744622267, 0.10280549802297119, 0.07129494907503638], 'brevity_penalty': 1.0, 'length_ratio': 1.024512987012987, 'translation_length': 6311, 'reference_length': 6160}
bleu_score_gpt3turbo_0shot = {'bleu': 0.08148879874051647, 'precisions': [0.33576110706482154, 0.09536527886881382, 0.047058823529411764, 0.029263746505125816], 'brevity_penalty': 1.0, 'length_ratio': 1.114448051948052, 'translation_length': 6865, 'reference_length': 6160}
bleu_score_gpt3turbo_0shot_cot = {'bleu': 0.08697922761548542, 'precisions': [0.34282777859345176, 0.10061796862620821, 0.05093787644123215, 0.03257390321973263], 'brevity_penalty': 1.0, 'length_ratio': 1.1056818181818182, 'translation_length': 6811, 'reference_length': 6160}
bleu_score_gpt3turbo_5shot = {'bleu': 0.11305024860296738, 'precisions': [0.3607077282590552, 0.12948461118193408, 0.07513524343818874, 0.052104208416833664], 'brevity_penalty': 0.9721851781791924, 'length_ratio': 0.972564935064935, 'translation_length': 5991, 'reference_length': 6160}
bleu_score_gpt3turbo_5shot_cot = {'bleu': 0.10186510840145463, 'precisions': [0.3596831282656329, 0.12037548315847597, 0.0658828299209406, 0.04398826979472141], 'brevity_penalty': 0.9624621132646293, 'length_ratio': 0.9631493506493507, 'translation_length': 5933, 'reference_length': 6160}
bleu_score_gpt3turbo_10shot = {'bleu': 0.14158054194841557, 'precisions': [0.3876788036410923, 0.15410474168435953, 0.09588509316770186, 0.0705073086844368], 'brevity_penalty': 0.998700455023816, 'length_ratio': 0.9987012987012988, 'translation_length': 6152, 'reference_length': 6160}
bleu_score_gpt3turbo_10shot_cot = {'bleu': 0.13563189443663268, 'precisions': [0.3786866547172886, 0.14688664183076106, 0.09149308935176173, 0.06750053914168644], 'brevity_penalty': 0.9962592545938909, 'length_ratio': 0.9962662337662338, 'translation_length': 6137, 'reference_length': 6160}
